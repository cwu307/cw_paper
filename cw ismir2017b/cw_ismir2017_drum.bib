% Example bibtex file for ISMIR Template


@book{Schedl2014,
author = {Schedl, Markus and G{\'{o}}mez, Emilia and Urbano, Juli{\'{a}}n},
booktitle = {Foundations and Trends{\textregistered} in Information Retrieval},
doi = {10.1561/1500000042},
file = {:Users/cw/Documents/Mendeley Desktop/Schedl, G{\'{o}}mez, Urbano/Foundations and Trends{\textregistered} in Information Retrieval/Schedl, G{\'{o}}mez, Urbano - 2014 - Music Information Retrieval Recent Developments and Applications.pdf:pdf},
isbn = {9781601988072},
issn = {1554-0669},
mendeley-groups = {MIR in general,0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal},
number = {2-3},
pages = {127--261},
title = {{Music Information Retrieval: Recent Developments and Applications}},
url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-information-retrieval/INR-042},
volume = {8},
publisher = {now publishers},
year = {2014}
}

@article{Benetos2013,
author = {Benetos, Emmanouil and Dixon, Simon and Giannoulis, Dimitrios and Kirchhoff, Holger and Klapuri, Anssi},
doi = {10.1007/s10844-013-0258-3},
file = {:Users/mac/Documents/Mendeley Desktop/Benetos et al/Journal of Intelligent Information Systems/Benetos et al. - 2013 - Automatic music transcription challenges and future directions.pdf:pdf},
issn = {0925-9902},
journal = {Journal of Intelligent Information Systems},
mendeley-groups = {Rhythm detection,Transcription,CW ISMIR 2014,CW ISMIR 2016,ICMPC14,0{\_}Thesis{\_}proposal},
month = {jul},
title = {{Automatic music transcription: challenges and future directions}},
url = {http://link.springer.com/10.1007/s10844-013-0258-3},
year = {2013}
}

@inproceedings{Wu2016,
author = {Wu, Chih-Wei and Lerch, Alexander},
booktitle = {Proceedings of International Society for Music Information Retrieval Conference (ISMIR)},
file = {:Users/cw/Documents/Mendeley Desktop/Wu, Lerch/Proceedings of International Society for Music Information Retrieval Conference (ISMIR)/Wu, Lerch - 2016 - On drum playing technique detection in polyphonic mixtures.pdf:pdf},
mendeley-groups = {0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {218--224},
title = {{On drum playing technique detection in polyphonic mixtures}},
year = {2016}
}

@inproceedings{Tindale2004,
author = {Tindale, Adam R. and Kapur, Ajay and Tzanetakis, George and Fujinaga, Ichiro},
booktitle = {Proceedings of the International Society of Music Information Retrieval Conference (ISMIR)},
file = {:Users/cw/Documents/Mendeley Desktop/Tindale et al/Proceedings of the International Society of Music Information Retrieval Conference (ISMIR)/Tindale et al. - 2004 - Retrieval of percussion gestures using timbre classification techniques.pdf:pdf},
mendeley-groups = {MIR in general/Playing Technique,0{\_}My{\_}working{\_}folders/CW ISMIR 2016,4{\_}Drum{\_}related,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {541--544},
title = {{Retrieval of percussion gestures using timbre classification techniques.}},
url = {http://www.ee.columbia.edu/{~}dpwe/ismir2004/CRFILES/paper235.pdf},
year = {2004}
}

@inproceedings{Prockup2013,
author = {Prockup, Matthew and Schmidt, E and Scott, Jeffrey and Kim, Youngmoo E.},
booktitle = {Proceedings of the International Society of Music Information Retrieval Conference (ISMIR)},
file = {:Users/cw/Documents/Mendeley Desktop/Prockup et al/Proceedings of the International Society of Music Information Retrieval Conference (ISMIR)/Prockup et al. - 2013 - Toward Understanding Expressive Percussion Through Content Based Analysis.pdf:pdf},
mendeley-groups = {MIR in general/Playing Technique,0{\_}My{\_}working{\_}folders/CW ISMIR 2016,0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,4{\_}Drum{\_}related,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
title = {{Toward Understanding Expressive Percussion Through Content Based Analysis.}},
url = {http://ismir2013.ismir.net/wp-content/uploads/2013/09/242{\_}Paper.pdf},
year = {2013}
}

@inproceedings{Dittmar2014,
author = {Dittmar, Christian and G{\"{a}}rtner, Daniel},
booktitle = {Proceedings of the International Conference on Digital Audio Effects (DAFX)},
file = {:Users/cw/Documents/Mendeley Desktop/Dittmar, G{\"{a}}rtner/Proceedings of the International Conference on Digital Audio Effects (DAFX)/Dittmar, G{\"{a}}rtner - 2014 - Real-time Transcription and Separation of Drum Recording Based on NMF Decomposition.pdf:pdf},
mendeley-groups = {0{\_}My{\_}working{\_}folders/CW ISMIR 2016,0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,MIR in general/Transcription,0{\_}My{\_}working{\_}folders/CW ISMIR 2015,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {1--8},
title = {{Real-time Transcription and Separation of Drum Recording Based on NMF Decomposition}},
url = {http://www.dafx14.fau.de/papers/dafx14{\_}christian{\_}dittmar{\_}real{\_}time{\_}transcription{\_}a.pdf},
year = {2014}
}

@inproceedings{Gillet2006,
abstract = {One of the main bottlenecks in the progress of the Music Information Retrieval (MIR) research field is the limited ac- cess to common, large and annotated audio databases that could serve for technology development and/or evaluation. The aim of this paper is to present in detail the ENST-Drums database, emphasizing on both the content and the recording process. This audiovisual database of drum performances by three professional drummers was recorded on 8 audio channels and 2 video channels. The drum sequences are fully annotated and will be, for a large part, freely distributed for research purposes. The large variety in its content should serve research in various domains of audio signal process- ing involving drums, ranging from single drum event clas- sification to complex multimodal drum track transcription and extraction from polyphonic music.},
author = {Gillet, Olivier and Richard, Ga{\"{e}}l},
booktitle = {Proceedings of International Society for Music Information Retrieval Conference (ISMIR)},
file = {:Users/cw/Documents/Mendeley Desktop/Gillet, Richard/Proceedings of International Society for Music Information Retrieval Conference (ISMIR)/Gillet, Richard - 2006 - Enst-drums an extensive audio-visual database for drum signals processing.pdf:pdf},
keywords = {aration,automatic drum transcrip-,campaign,drum event detection in,for example,multimodal music transcription,polyphonic music,research database,source sep-,the database used for,the mami,tion},
mendeley-groups = {MIR in general/Playing Technique,0{\_}My{\_}working{\_}folders/CW ISMIR 2014,0{\_}My{\_}working{\_}folders/CW ISMIR 2016,MIR in general,0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,4{\_}Drum{\_}related,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
title = {{Enst-drums: an extensive audio-visual database for drum signals processing}},
url = {http://ismir2006.ismir.net/PAPERS/ISMIR0627{\_}Paper.pdf},
year = {2006}
}

@book{Chapelle2006,
abstract = {Pattern recognition methods could be of great help to disease diagnosis. In this study, a semi-supervised learning based method, Laplacian support vector machine (LapSVM), was used in diabetes diseases prediction. The diabetes disease dataset used in this article is Pima Indians diabetes dataset obtained from the UCI Repository of Machine Learning Databases and all patients in the dataset are females at least 21 years old of Pima Indian heritage. Firstly, LapSVM was trained as a fully-supervised learning classifier to predict diabetes dataset and 79.17{\%} accuracy was obtained. Then, it was trained as a semi-supervised learning classifier and we got the prediction accuracy 82.29{\%}. The obtained accuracy 82.29{\%} is higher than other previous reports. The experiments led to the finding that LapSVM offers a very promising application, i.e., LapSVM can be used to solve a fully-supervised learning problem by solving a semi-supervised learning problem. The result suggests that LapSVM can be of great help to physicians in the process of diagnosing diabetes disease and it could be a very promising method in the situations where a lot of data are not class-labeled.},
author = {Chapelle, Olivier and Sch{\"{o}}lkopf, Bernhard and Zien, Alexander},
doi = {10.1007/s12539-009-0016-2},
file = {:Users/cw/Documents/Mendeley Desktop/Chapelle, Sch{\"{o}}lkopf, Zien/Unknown/Chapelle, Sch{\"{o}}lkopf, Zien - 2006 - Semi-Supervised Learning.pdf:pdf},
isbn = {9780262033589},
issn = {19132751},
mendeley-groups = {0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,MIR in general/Semi-supervised Learning,0{\_}My{\_}working{\_}folders/0{\_}Qualifying{\_}exam,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pmid = {20640829},
publisher = {The MIT Press},
title = {{Semi-Supervised Learning}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21243728},
year = {2006}
}

@inproceedings{Raina2007a,
abstract = {We present a new machine learning framework called "self-taught learning" for using unlabeled data in supervised classification tasks. We do not assume that the unlabeled data follows the same class labels or generative distribution as the labeled data. Thus, we would like to use a large number of unlabeled images (or audio samples, or text documents) randomly downloaded from the Internet to improve performance on a given image (or audio, or text) classification task. Such unlabeled data is significantly easier to obtain than in typical semi-supervised or transfer learning settings, making self-taught learning widely applicable to many practical learning problems. We describe an approach to self-taught learning that uses sparse coding to construct higher-level features using the unlabeled data. These features form a succinct input representation and significantly improve classification performance. When using an SVM for classification, we further show how a Fisher kernel can be learned for this representation.},
author = {Raina, Rajat and Battle, Alexis and Lee, Honglak and Packer, Benjamin and Ng, Andrew Y},
booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
doi = {10.1145/1273496.1273592},
file = {:Users/cw/Documents/Mendeley Desktop/Raina et al/Proceedings of the International Conference on Machine Learning (ICML)/Raina et al. - 2007 - Self-taught learning transfer learning from unlabeled data.pdf:pdf},
isbn = {1595937935},
issn = {1595937935},
mendeley-groups = {MIR in general/Feature Learning,0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {759--766},
title = {{Self-taught learning: transfer learning from unlabeled data}},
year = {2007}
}

@article{Jao2015,
abstract = {Tagging music signals with semantic labels such as genres, moods and instruments is important for content-based music retrieval and recommendation. While considerable effort has been made, automatic music annotation is still considered challenging due to the difficulty of extracting good audio features that capture the characteristics of different tags. To address this issue, we present in this letter two exemplar-based approaches that represent the content of a music clip by referring to a large set of unlabeled audio exemplars. The first approach represents a music clip by the set of audio exemplars that is highly correlated with the short-time feature vectors of the clip, whereas the second approach represents a music clip as sparse linear combinations of its short-time feature vectors over the audio exemplars. Music annotation is then performed by learning the relevance of the audio examples to different tags using labeled data. These two approaches effectively capitalize the availability of unlabeled data to explore the commonality of music signals to find out tag-specific acoustic patterns, without domain knowledge and feature design. Evaluation on the CAL10k music genre tagging dataset for tag-based music retrieval shows that, with thousands of unlabeled audio examples randomly drawn from the Million Song Dataset, the proposed approaches lead to remarkably higher precision rates than existing approaches.},
author = {Jao, Ping-Keng and Yang, Yi-Hsuan},
doi = {10.1109/LSP.2015.2433061},
file = {:Users/cw/Documents/Mendeley Desktop/Jao, Yang/Signal Processing Letters, IEEE/Jao, Yang - 2015 - Music Annotation and Retrieval using Unlabeled Exemplars Correlation and Sparse Codes.pdf:pdf},
isbn = {1070-9908 VO - 22},
issn = {1070-9908},
journal = {Signal Processing Letters, IEEE},
mendeley-groups = {1{\_}MUST{\_}READ,0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
number = {10},
pages = {1771--1775},
title = {{Music Annotation and Retrieval using Unlabeled Exemplars: Correlation and Sparse Codes}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=7106493},
volume = {22},
year = {2015}
}

@inproceedings{Wu2013a,
author = {Wu, Bin and Zhong, Erheng and Hu, Derek Hao and Horner, Andrew and Yang, Qiang},
booktitle = {SIAM conference on Data Mining},
file = {:Users/cw/Documents/Mendeley Desktop/Wu et al/SIAM conference on Data Mining/Wu et al. - 2013 - SMART Semi-Supervised Music Emotion Recognition with Social Tagging.pdf:pdf},
isbn = {9781611972627},
mendeley-groups = {0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,0{\_}My{\_}working{\_}folders/0{\_}Qualifying{\_}exam,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {279--287},
title = {{SMART : Semi-Supervised Music Emotion Recognition with Social Tagging}},
year = {2013}
}

@inproceedings{Vogl2017,
author = {Vogl, Richard and Dorfer, Matthias and Knees, Peter},
booktitle = {Proceedings of the International Conference on Acoustics Speech and Signal Processing (ICASSP)},
file = {:Users/cw/Documents/Mendeley Desktop/Vogl, Dorfer, Knees/Proceedings of the International Conference on Acoustics Speech and Signal Processing (ICASSP)/Vogl, Dorfer, Knees - 2017 - Drum Transcription From Polyphonic Music With Recurrent Neural Networks.pdf:pdf},
isbn = {9781509041176},
mendeley-groups = {4{\_}Drum{\_}related,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {201--205},
title = {{Drum Transcription From Polyphonic Music With Recurrent Neural Networks}},
year = {2017}
}

@article{Gillet2008,
author = {Gillet, Olivier and Richard, Ga{\"{e}}l},
doi = {10.1109/TASL.2007.914120},
file = {:Users/cw/Documents/Mendeley Desktop/Gillet, Richard/IEEE Transactions on Audio, Speech and Language Processing/Gillet, Richard - 2008 - Transcription and separation of drum signals from polyphonic music.pdf:pdf},
issn = {1558-7916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
mendeley-groups = {0{\_}My{\_}working{\_}folders/CW ISMIR 2014,0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,4{\_}Drum{\_}related,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
month = {March},
number = {3},
pages = {529--540},
title = {{Transcription and separation of drum signals from polyphonic music}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4443887 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4443887},
volume = {16},
year = {2008}
}

@incollection{FitzGerald2006,
author = {FitzGerald, Derry and Paulus, Jouni},
booktitle = {Signal Processing Methods for Music Transcription},
file = {:Users/cw/Documents/Mendeley Desktop/FitzGerald, Paulus/Signal Processing Methods for Music Transcription/FitzGerald, Paulus - 2006 - Unpitched percussion transcription.pdf:pdf},
mendeley-groups = {0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,4{\_}Drum{\_}related,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
publisher = {Springer},
title = {{Unpitched percussion transcription}},
url = {http://www.springerlink.com/index/w4175761l68h5t85.pdf},
year = {2006}
}

@article{Yoshii2007b,
abstract = {This paper describes a system that detects onsets of the bass drum, snare drum, and hi-hat cymbals in polyphonic audio signals of popular songs. Our system is based on a template-matching method that uses power spectrograms of drum sounds as templates. This method calculates the distance between a template and each spectrogram segment extracted from a song spectrogram, using Goto's distance measure originally designed to detect the onsets in drums-only signals. However, there are two main problems. The first problem is that appropriate templates are unknown for each song. The second problem is that it is more difficult to detect drum-sound onsets in sound mixtures including various sounds other than drum sounds. To solve these problems, we propose template-adaptation and harmonic-structure-suppression methods. First of all, an initial template of each drum sound, called a seed template, is prepared. The former method adapts it to actual drum-sound spectrograms appearing in the song spectrogram. To make our system robust to the overlapping of harmonic sounds with drum sounds, the latter method suppresses harmonic components in the song spectrogram before the adaptation and matching. Experimental results with 70 popular songs showed that our template-adaptation and harmonic-structure-suppression methods improved the recognition accuracy and achieved 83{\%}, 58{\%}, and 46{\%} in detecting onsets of the bass drum, snare drum, and hi-hat cymbals, respectively},
author = {Yoshii, Kazuyoshi and Goto, Masataka and Okuno, Hiroshi G.},
doi = {10.1109/TASL.2006.876754},
file = {:Users/cw/Documents/Mendeley Desktop/Yoshii, Goto, Okuno/IEEE Transactions on Audio, Speech and Language Processing/Yoshii, Goto, Okuno - 2007 - Drum sound recognition for polyphonic audio signals by adaptation and matching of spectrogram templates wit.pdf:pdf},
issn = {15587916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Drum sound recognition,Harmonic structure suppression,Polyphonic audio signal,Spectrogram template,Template adaptation,Template matching},
mendeley-groups = {4{\_}Drum{\_}related,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
number = {1},
pages = {333--345},
title = {{Drum sound recognition for polyphonic audio signals by adaptation and matching of spectrogram templates with harmonic structure suppression}},
volume = {15},
year = {2007}
}

@inproceedings{Gajhede2016,
author = {Gajhede, Nicolai and Beck, Oliver and Purwins, Hendrik},
booktitle = {Proceedings of the Audio Mostly},
file = {:Users/cw/Documents/Mendeley Desktop/Gajhede, Beck, Purwins/Proceedings of the Audio Mostly/Gajhede, Beck, Purwins - 2016 - Convolutional Neural Networks with Batch Normalization for Classifying Hi-hat, Snare, and Bass Percussio.pdf:pdf},
isbn = {9781450348225},
keywords = {convolutional neural networks,musical instrument classification},
mendeley-groups = {4{\_}Drum{\_}related,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {111--115},
title = {{Convolutional Neural Networks with Batch Normalization for Classifying Hi-hat, Snare, and Bass Percussion Sound Samples}},
year = {2016}
}


@inproceedings{Zils2002,
author = {Zils, Aymeric and Pachet, Fran{\c{c}}ois and Delerue, Olivier and Gouyon, Fabien},
booktitle = {Proceedings of the International Conference on Web Delivering of Music (WedelMusic)},
file = {:Users/cw/Documents/Mendeley Desktop/Zils et al/Proceedings of the International Conference on Web Delivering of Music (WedelMusic)/Zils et al. - 2002 - Automatic extraction of drum tracks from polyphonic music signals.pdf:pdf},
isbn = {0769518621},
mendeley-groups = {4{\_}Drum{\_}related,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {7--11},
title = {{Automatic extraction of drum tracks from polyphonic music signals}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1176209},
year = {2002}
}

@inproceedings{Wu2015a,
author = {Wu, Chih-Wei and Lerch, Alexander},
booktitle = {Proceedings of International Society for Music Information Retrieval Conference (ISMIR)},
file = {:Users/cw/Documents/Mendeley Desktop/Wu, Lerch/Proceedings of International Society for Music Information Retrieval Conference (ISMIR)/Wu, Lerch - 2015 - Drum transcription using partially fixed non-negative matrix factorization with template adaptation.pdf:pdf},
mendeley-groups = {0{\_}My{\_}working{\_}folders/CW ISMIR 2016,0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,0{\_}My{\_}working{\_}folders/CW ISMIR 2015,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {257--263},
title = {{Drum transcription using partially fixed non-negative matrix factorization with template adaptation}},
year = {2015}
}

@inproceedings{Roebel2015,
abstract = {This paper presents an investigation into the detection and classifica-tion of drum sounds in polyphonic music and drum loops using non-negative matrix deconvolution (NMD) and the Itakura Saito diver-gence. The Itakura Saito divergence has recently been proposed as especially appropriate for decomposing audio spectra due to the fact that it is scale invariant, but it has not yet been widely adopted. The article studies new contributions for audio event detection methods using the Itakura Saito divergence that improve efficiency and nu-merical stability, and simplify the generation of target pattern sets. A new approach for handling background sounds is proposed and moreover, a new detection criteria based on estimating the percep-tual presence of the target class sources is introduced. Experimental results obtained for drum detection in polyphonic music and drum soli demonstrate the beneficial effects of the proposed extensions.},
author = {Roebel, Axel and Pons, Jordi and Liuni, Marco and Lagrange, Mathieu},
booktitle = {Proceedings of the International Conference on Acoustics Speech and Signal Processing (ICASSP)},
file = {:Users/cw/Documents/Mendeley Desktop/Roebel et al/Proceedings of the International Conference on Acoustics Speech and Signal Processing (ICASSP)/Roebel et al. - 2015 - On Automatic Drum Transcription Using Non-Negative Matrix Deconvolution and Itakura Saito Divergence.pdf:pdf},
keywords = {Index Terms— Source separation,audio event detection,drum transcription,music information retrieval,non-negative matrix deconvolution},
mendeley-groups = {MIR in general/Playing Technique,0{\_}My{\_}working{\_}folders/CW ISMIR 2016,0{\_}My{\_}working{\_}folders/Summer@Dolby{\_}2015,4{\_}Drum{\_}related,0{\_}My{\_}working{\_}folders,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
title = {{On Automatic Drum Transcription Using Non-Negative Matrix Deconvolution and Itakura Saito Divergence}},
year = {2015}
}

@article{Hinton2006,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee-Whye},
file = {:Users/cw/Documents/Mendeley Desktop/Hinton, Osindero, Teh/Neural computation/Hinton, Osindero, Teh - 2006 - A Fast Learning Algorithm for Deep Belief Nets.pdf:pdf},
journal = {Neural computation},
mendeley-groups = {0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,MIR in general/Deep Learning,0{\_}My{\_}working{\_}folders/0{\_}Qualifying{\_}exam},
pages = {1527--1554},
title = {{A Fast Learning Algorithm for Deep Belief Nets}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.2006.18.7.1527},
volume = {1554},
year = {2006}
}

@inproceedings{Vogl2016,
author = {Vogl, Richard. and Dorfer, Matthias and Knees, Peter},
booktitle = {Proceedings of International Society for Music Information Retrieval Conference (ISMIR)},
file = {:Users/cw/Documents/Mendeley Desktop/Vogl, Dorfer, Knees/Proceedings of International Society for Music Information Retrieval Conference (ISMIR)/Vogl, Dorfer, Knees - 2016 - Recurrent Neural Networks for Drum Transcription.pdf:pdf},
mendeley-groups = {1{\_}MUST{\_}READ,0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,4{\_}Drum{\_}related,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {730--736},
title = {{Recurrent Neural Networks for Drum Transcription}},
year = {2016}
}

@inproceedings{Southall2016,
abstract = {Automatic drum transcription (ADT) systems attempt to generate a symbolic music notation for percussive in-struments in audio recordings. Neural networks have al-ready been shown to perform well in fields related to ADT such as source separation and onset detection due to their utilisation of time-series data in classification. We pro-pose the use of neural networks for ADT in order to ex-ploit their ability to capture a complex configuration of fea-tures associated with individual or combined drum classes. In this paper we present a bi-directional recurrent neu-ral network for offline detection of percussive onsets from specified drum classes and a recurrent neural network suit-able for online operation. In both systems, a separate net-work is trained to identify onsets for each drum class under observation—that is, kick drum, snare drum, hi-hats, and combinations thereof. We perform four evaluations utilis-ing the IDMT-SMT-Drums and ENST minus one datasets, which cover solo percussion and polyphonic audio respec-tively. The results demonstrate the effectiveness of the pre-sented methods for solo percussion and a capacity for iden-tifying snare drums, which are historically the most diffi-cult drum class to detect.},
author = {Southall, Carl and Stables, Ryan and Hockman, Jason},
booktitle = {Proceedings of International Society for Music Information Retrieval Conference (ISMIR)},
file = {:Users/cw/Documents/Mendeley Desktop/Southall, Stables, Hockman/Proceedings of International Society for Music Information Retrieval Conference (ISMIR)/Southall, Stables, Hockman - 2016 - Automatic Drum Transcription Using Bi-Directional Recurrent Neural Networks.pdf:pdf},
mendeley-groups = {0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,MIR in general/Transcription,4{\_}Drum{\_}related,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
title = {{Automatic Drum Transcription Using Bi-Directional Recurrent Neural Networks}},
year = {2016}
}

@article{Li2014,
abstract = {Deep neural network (DNN) obtains significant accuracy improvements on many speech recognition tasks and its power comes from the deep and wide network structure with a very large number of parameters. It becomes challenging when we deploy DNN on devices which have limited computational and storage resources. The common practice is to train a DNN with a small number of hidden nodes and a small senone set using the standard training process, leading to significant accuracy loss. In this study, we propose to better address these issues by utilizing the DNN output distribution. To learn a DNN with small number of hidden nodes, we minimize the Kullback-Leibler divergence between the output distributions of the small-size DNN and a standard large-size DNN by utilizing a large number of un-transcribed data. For better senone set generation, we cluster the senones in the large set into a small one by directly relating the clustering process to DNN parameters, as opposed to decoupling the senone generation and DNN training process in the standard training. Evaluated on a short message dictation task, the proposed two methods get 5.08{\%} and 1.33{\%} relative word error rate reduction from the standard training method, respectively.},
author = {Li, Jinyu and Zhao, Rui and Huang, Jui Ting and Gong, Yifan},
file = {:Users/cw/Documents/Mendeley Desktop/Li et al/Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH/Li et al. - 2014 - Learning small-size DNN with output-distribution-based criteria.PDF:PDF},
issn = {19909772},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
keywords = {DNN,Device,Learning,Model compression,Output distribution},
mendeley-groups = {MIR in general/Deep Learning,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {1910--1914},
title = {{Learning small-size DNN with output-distribution-based criteria}},
year = {2014}
}

@article{Hinton2015,
abstract = {A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.},
archivePrefix = {arXiv},
arxivId = {1503.02531},
author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
doi = {10.1063/1.4931082},
eprint = {1503.02531},
file = {:Users/cw/Documents/Mendeley Desktop/Hinton, Vinyals, Dean/arXiv1503.02531/Hinton, Vinyals, Dean - 2015 - Distilling the Knowledge in a Neural Network.pdf:pdf},
issn = {0022-2488},
journal = {arXiv:1503.02531},
mendeley-groups = {0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,MIR in general/Deep Learning,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {1--9},
title = {{Distilling the Knowledge in a Neural Network}},
url = {http://arxiv.org/abs/1503.02531},
year = {2015}
}


@inproceedings{Watanabe2017,
author = {Watanabe, Shinji and Hori, Takaaki and Roux, Jonathan L. and Hershey, John R.},
booktitle = {Proceedings of the International Conference on Acoustics Speech and Signal Processing (ICASSP)},
file = {:Users/cw/Documents/Mendeley Desktop/Watanabe et al/Proceedings of the International Conference on Acoustics Speech and Signal Processing (ICASSP)/Watanabe et al. - 2017 - Student-Teacher Network Learning with Enhanced Features.pdf:pdf},
isbn = {9781509041176},
mendeley-groups = {MIR in general/Knowledge distillation,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {5275--5279},
title = {{Student-Teacher Network Learning with Enhanced Features}},
year = {2017}
}

@inproceedings{Cui2017,
author = {Cui, Jia and Kingsbury, Brian and Ramabhadran, Bhuvana and Saon, George and Sercu, Tom and Audhkhasi, Kartik and Sethy, Abhinav and Nussbaum-Thom, Markus and Rosenberg, Andrew},
booktitle = {Proceedings of the International Conference on Acoustics Speech and Signal Processing (ICASSP)},
file = {:Users/cw/Documents/Mendeley Desktop/Cui et al/Proceedings of the International Conference on Acoustics Speech and Signal Processing (ICASSP)/Cui et al. - 2017 - Knowledge Distillation Across Ensembles of Multiplingual Models for Low-resource Languages.pdf:pdf},
isbn = {9781509041176},
mendeley-groups = {MIR in general/Knowledge distillation,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {4825--4829},
title = {{Knowledge Distillation Across Ensembles of Multiplingual Models for Low-resource Languages}},
year = {2017}
}


@inproceedings{Thompson2014,
author = {Thompson, Lucas and Mauch, Matthias and Dixon, Simon},
booktitle = {Proceedings of International Society for Music Information Retrieval Conference (ISMIR)},
file = {:Users/cw/Documents/Mendeley Desktop/Thompson, Mauch, Dixon/Proceedings of International Society for Music Information Retrieval Conference (ISMIR)/Thompson, Mauch, Dixon - 2014 - Drum Transcription via Classification of Bar-Level Rhythmic Patterns.pdf:pdf},
mendeley-groups = {0{\_}My{\_}working{\_}folders/CW ISMIR 2016,0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,MIR in general/Transcription,4{\_}Drum{\_}related,0{\_}My{\_}working{\_}folders/CW ISMIR 2015,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
title = {{Drum Transcription via Classification of Bar-Level Rhythmic Patterns}},
url = {http://matthiasmauch.de/{\_}pdf/thompson2014drum.pdf},
year = {2014}
}

@article{Paulus2009a,
author = {Paulus, Jouni and Klapuri, Anssi},
doi = {10.1155/2009/497292},
file = {:Users/cw/Documents/Mendeley Desktop/Paulus, Klapuri/EURASIP Journal on Audio, Speech, and Music Processing/Paulus, Klapuri - 2009 - Drum Sound Detection in Polyphonic Music with Hidden Markov Models.pdf:pdf},
issn = {1687-4714},
journal = {EURASIP Journal on Audio, Speech, and Music Processing},
mendeley-groups = {0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,MIR in general/Transcription,4{\_}Drum{\_}related,0{\_}My{\_}working{\_}folders/CW ISMIR 2015,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {1--9},
title = {{Drum Sound Detection in Polyphonic Music with Hidden Markov Models}},
url = {http://asmp.eurasipjournals.com/content/2009/1/497292},
volume = {2009},
year = {2009}
}

@book{Lerch2012,
abstract = {With the proliferation of digital audio distribution over digital media, audio content analysis is fast becoming a requirement for designers of intelligent signal-adaptive audio processing systems. Written by a well-known expert in the field, this book provides quick access to different analysis algorithms and allows comparison between different approaches to the same task, making it useful for newcomers to audio signal processing and industry experts alike. A review of relevant fundamentals in audio signal processing, psychoacoustics, and music theory, as well as downloadable MATLAB files are also included.Please visit the companion website: www.AudioContentAnalysis.org},
author = {Lerch, Alexander},
isbn = {1118393503},
mendeley-groups = {0{\_}My{\_}working{\_}folders/ICMPC14,0{\_}My{\_}working{\_}folders/0{\_}Thesis{\_}proposal,0{\_}My{\_}working{\_}folders/CW ISMIR 2015,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {272},
publisher = {John Wiley {\&} Sons},
title = {{An Introduction to Audio Content Analysis: Applications in Signal Processing and Music Informatics}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=YSPT1LJqTbIC{\&}pgis=1},
year = {2012}
}

@inproceedings{Bucilua2006,
abstract = {Often the best performing supervised learning models are ensembles of hundreds or thousands of base-level classifiers. Unfortunately, the space required to store this many classifiers, and the time required to execute them at run-time, prohibits their use in applications where test sets are large (e.g. Google), where storage space is at a premium (e.g. PDAs), and where computational power is limited (e.g. hea-ring aids). We present a method for "compressing" large, complex ensembles into smaller, faster models, usually without significant loss in performance.},
author = {Buciluǎ, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
booktitle = {Proceedings of the International conference on Knowledge Discovery and Data mining (SIGKDD)},
doi = {10.1145/1150402.1150464},
file = {:Users/cw/Documents/Mendeley Desktop/Buciluǎ, Caruana, Niculescu-Mizil/Proceedings of the International conference on Knowledge Discovery and Data mining (SIGKDD)/Buciluǎ, Caruana, Niculescu-Mizil - 2006 - Model compression.pdf:pdf},
isbn = {1595933395},
keywords = {model compression,supervised learning},
mendeley-groups = {MIR in general/Deep Learning,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {535},
title = {{Model compression}},
url = {http://portal.acm.org/citation.cfm?doid=1150402.1150464},
year = {2006}
}

@article{Ioffe2015,
abstract = {{Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch{\}}. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9{\%} top-5 validation error (and 4.8{\%} test error), exceeding the accuracy of human raters.},
archivePrefix = {arXiv},
arxivId = {1502.03167},
author = {Ioffe, Sergey and Szegedy, Christian},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {1502.03167},
file = {:Users/cw/Documents/Mendeley Desktop/Ioffe, Szegedy/Arxiv/Ioffe, Szegedy - 2015 - Batch Normalization Accelerating Deep Network Training by Reducing Internal Covariate Shift.pdf:pdf},
isbn = {9780874216561},
issn = {0717-6163},
journal = {Arxiv},
mendeley-groups = {MIR in general/Deep Learning,0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {1--11},
pmid = {15003161},
title = {{Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift}},
url = {http://arxiv.org/abs/1502.03167},
year = {2015}
}

@inproceedings{Kingma2015,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions. The method is straightforward to implement and is based on adaptive estimates of lower-order moments of the gradients. The method is computationally efficient, has little memory requirements and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The method exhibits invariance to diagonal rescaling of the gradients by adapting to the geometry of the objective function. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. We demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods.},
archivePrefix = {arXiv},
arxivId = {1412.6980},
author = {Kingma, Diederik P. and Ba, Jimmy Lei},
booktitle = {International Conference on Learning Representations (ICLR)},
eprint = {1412.6980},
file = {:Users/cw/Documents/Mendeley Desktop/Kingma, Ba/International Conference on Learning Representations (ICLR)/Kingma, Ba - 2015 - Adam a Method for Stochastic Optimization.pdf:pdf},
mendeley-groups = {0{\_}My{\_}working{\_}folders/CW ISMIR 2017DRUM},
pages = {1--15},
title = {{Adam: a Method for Stochastic Optimization}},
year = {2015}
}

